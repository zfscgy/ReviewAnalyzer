{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import os\n",
    "os.environ['https_proxy'] = \"10.192.132.179:10811\"\n",
    "\n",
    "\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "config = json.load(open(\"./secret_config.json\"))\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=config[\"openai_key\"], base_url=\"https://api.132999.xyz/v1/\")\n",
    "\n",
    "def get_gpt_response(user_texts: List[str]):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"你是一个智慧的商业分析员，你会根据用户购买商品后的评价来判断其是否是消极或者积极；并且选择出用户评价的主要因素，\\\n",
    "                    从（造型、颜色、图案、风格、尺寸、包装、材质、工艺、实用性、文化、情感、审美、品质、物流、价格）这里面选一个产生评价的最主要因素（若无法确定，则为其他）。\\\n",
    "                    接下来我将会每一行输入一个用户评价。你将返回你的分析结果，每一行分别返回：[原始评价];[积极或消极];[因素]。\\\n",
    "                    用【英文分号，也就是';'】分隔。例如对于\\\"太贵了\\\"这条评价，你将会返回\\\"太贵了;消极;价格\\\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\\n\".join(user_texts)\n",
    "            }\n",
    "    ])\n",
    "    try:\n",
    "        resps = response.choices[0].message.content.split(\"\\n\")\n",
    "        if len(resps) != len(user_texts):\n",
    "            resps += (len(user_texts) - len(resps)) * [\"\"]\n",
    "            print(\"注：此时GPT的回复数缺失！已经靠后补全\")\n",
    "        return resps\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/故宫纪念品评价-清洗后.csv\", encoding=\"utf-8\", lineterminator='\\n')\n",
    "df.loc[:, 'content'] = df['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt_emotion'] = \"\"\n",
    "df['gpt_factor'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填补未产生GPT回复的\n",
    "\n",
    "df['content'] = df['content'].astype(str)\n",
    "df['content'] = df['content'].str.strip()\n",
    "df['content'] = df['content'].str.replace('\\x01', '')\n",
    "df['content'] = df['content'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprocessed:  18\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "540",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3081\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3082\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1625\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1632\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 540",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m unparsed_contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i_start, \u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt_emotion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     13\u001b[0m         unparsed_indices\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m     14\u001b[0m         unparsed_contents\u001b[38;5;241m.\u001b[39mappend(df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexing.py:889\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    887\u001b[0m             \u001b[38;5;66;03m# AttributeError for IntervalTree get_value\u001b[39;00m\n\u001b[0;32m    888\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexing.py:1060\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: Tuple):\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m-> 1060\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_tuple(tup)\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexing.py:807\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m    805\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m    810\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m    813\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m    814\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexing.py:1124\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\generic.py:3739\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected label or tuple of labels, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   3738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3739\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   3742\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3083\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3083\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3086\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tolerance(tolerance, np\u001b[38;5;241m.\u001b[39masarray(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 540"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ChatGPT分析结果.csv\", dtype={\n",
    "    \"content\": 'string', 'gpt_emotion': 'string', 'gpt_factor': 'string'\n",
    "}, keep_default_na=False, index_col=0)\n",
    "df = df[(df['content'] !=  \"此用户没有填写评价。\") & (df['content'] != \"\")]\n",
    "\n",
    "print(\"Unprocessed: \", (df['gpt_emotion']==\"\").sum())\n",
    "i_start = 0\n",
    "while True:\n",
    "    unparsed_indices = []\n",
    "    unparsed_contents = []\n",
    "    for i in range(i_start, len(df)):\n",
    "        if df.loc[i, 'gpt_emotion'] == \"\":\n",
    "            unparsed_indices.append(i)\n",
    "            unparsed_contents.append(df.loc[i, 'content'])\n",
    "            if len(unparsed_indices) == 10:\n",
    "                break\n",
    "    i_start = i + 1\n",
    "\n",
    "    print(\"Contents\", unparsed_contents)\n",
    "    try:\n",
    "        resps = get_gpt_response(unparsed_contents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "    print(\"Resps\", resps)\n",
    "    resp_dict = dict()\n",
    "    for r in resps:\n",
    "        try:\n",
    "            content, emotion, factor = r.split(\";\")\n",
    "            resp_dict[content] = (emotion, factor)\n",
    "        except:\n",
    "            print(\"Fail to parse\", r)\n",
    "    \n",
    "    current_parsed = 0\n",
    "    for j in unparsed_indices:\n",
    "        content = df.loc[j, 'content']\n",
    "        if content in resp_dict:\n",
    "            emotion, factor = resp_dict[content]\n",
    "            df.loc[j, 'gpt_emotion'] = emotion\n",
    "            df.loc[j, 'gpt_factor'] = factor\n",
    "            current_parsed += 1\n",
    "    print(f\"Parsed {current_parsed} contents.\")\n",
    "    df.to_csv(\"data/ChatGPT分析结果.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents ['宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买']\n",
      "Resps ['宝贝收到了，质量很不错，包装精致，材质优秀，比想象中好，送礼自用非常合适，下次继续购买;积极;品质']\n",
      "Contents ['漂亮，有特色，比较贵的防尘口罩，各两盒共40个要73元，双十一的价钱，']\n",
      "Resps ['漂亮，有特色，比较贵的防尘口罩，各两盒共40个要73元，双十一的价钱;积极;价格']\n",
      "Contents ['質量非常好,與賣家描述的完全一致, 真的很喜歡,完全超出期望值,發貨速 度非常快,包裝非常仔細、嚴實,物流公司服務態度很好,運送速度很快,很滿意的一次購物質量很好, 希望更多的朋友信賴. 店主態度特好, 我會再次光顧的好賣家 贊，發貨迅速，態度很好，很滿意！很好很好！網上購物這麼激烈，沒想到店家的服務這麼好，商品質量好而價低廉， 很熱情的賣家，下次還來希望下次還有機會合作祝你生意興隆質量非常好，出乎我的意料包裝非常仔細。下次有機會再找你，店家人蠻好的，東東很不錯,淘到心意的寶貝是一件讓人很開心的事，比心??????????????? 質量非常好,與賣家描述的完全一致, 真的很喜歡,完全超出期望值,發貨速 度非常快,包裝非常仔細、嚴實,物流公司服務態度很好,運送速度很快']\n",
      "Resps ['質量非常好,與賣家描述的完全一致, 真的很喜歡,完全超出期望值,發貨速度非常快,包裝非常仔細、嚴實,物流公司服務態度很好,運送速度很快,很滿意的一次購物;积极;品质']\n",
      "Contents ['送朋友的，朋友比较喜欢，但是元素方面可以淡一点，少一点。          学习下元青花以及wedgwood，走素雅路线比较好。']\n",
      "Resps ['送朋友的，朋友比较喜欢，但是元素方面可以淡一点，少一点；积极;风格']\n",
      "Fail to parse 送朋友的，朋友比较喜欢，但是元素方面可以淡一点，少一点；积极;风格\n",
      "Contents ['送朋友的，朋友比较喜欢，但是元素方面可以淡一点，少一点。          学习下元青花以及wedgwood，走素雅路线比较好。']\n",
      "Resps ['送朋友的;积极;风格']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Resps []\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Resps []\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "Contents ['做工很一般，金属框有明显缝隙懒得退了，送老外的。  隔了两天才发出，还要托人给带过去。']\n",
      "注：此时GPT的回复数缺失！已经靠后补全\n",
      "Resps ['做工很一般，金属框有明显缝隙懒得退了，送老外的;消极;质量  ', '隔了两天才发出，还要托人给带过去;消极;物流']\n",
      "Contents ['很好的产品，相当好的质量五星评价。赞\\r 待朋友拆封后看到实物再予以追评。赞']\n",
      "注：此时GPT的回复数缺失！已经靠后补全\n",
      "Resps ['很好的产品，相当好的质量五星评价;积极;品质', '待朋友拆封后看到实物再予以追评;积极;其他']\n",
      "Contents ['这款帽子 胜在图案 颜色 漂亮，做工不错。\\r 面料比较厚，不太适合大夏天。\\r 头围 57，戴上紧紧地刚好。']\n",
      "Resps ['这款帽子 胜在图案 颜色 漂亮，做工不错;积极;图案']\n",
      "Contents ['外观材质：送别人的结婚礼物，包装还不错，但是盒子里面的包装比较一般。￼']\n",
      "Resps ['外观材质：送别人的结婚礼物，包装还不错，但是盒子里面的包装比较一般；积极;包装']\n",
      "Fail to parse 外观材质：送别人的结婚礼物，包装还不错，但是盒子里面的包装比较一般；积极;包装\n",
      "Contents ['外观材质：送别人的结婚礼物，包装还不错，但是盒子里面的包装比较一般。￼']\n",
      "Resps ['外观材质：送别人的结婚礼物，包装还不错，但是盒子里面的包装比较一般; 积极; 包装']\n",
      "Contents ['设']\n",
      "Resps ['对不起，我没能理解你的问题。你想要分析哪条评价？']\n",
      "Fail to parse 对不起，我没能理解你的问题。你想要分析哪条评价？\n",
      "Contents ['设']\n",
      "Resps ['抱歉，您的输入不太明确。您是想进行商品评价分析吗？如果是，请输入用户评价，我会帮您进行分析。']\n",
      "Fail to parse 抱歉，您的输入不太明确。您是想进行商品评价分析吗？如果是，请输入用户评价，我会帮您进行分析。\n",
      "Contents ['设']\n",
      "注：此时GPT的回复数缺失！已经靠后补全\n",
      "Resps ['我将使用自然语言处理和情感分析的技术来进行分析。请按照以下格式输入用户评价：', '', '[原始评价]', '', '例如：太贵了', '', '请注意：英文分号（;）用于分隔每一行评价。']\n",
      "Fail to parse 我将使用自然语言处理和情感分析的技术来进行分析。请按照以下格式输入用户评价：\n",
      "Fail to parse \n",
      "Fail to parse [原始评价]\n",
      "Fail to parse \n",
      "Fail to parse 例如：太贵了\n",
      "Fail to parse \n",
      "Fail to parse 请注意：英文分号（;）用于分隔每一行评价。\n",
      "Contents ['设']\n",
      "Resps ['我不确定你的输入是什么意思，请重新描述或者提问。']\n",
      "Fail to parse 我不确定你的输入是什么意思，请重新描述或者提问。\n",
      "Contents ['设']\n",
      "Resps ['设;其他;其他']\n",
      "Contents ['流沙杯垫金灿灿的，转起来非常解压！   兔子奔月，很可爱啊']\n",
      "注：此时GPT的回复数缺失！已经靠后补全\n",
      "Resps ['流沙杯垫金灿灿的，转起来非常解压！;积极;实用性  ', '兔子奔月，很可爱啊;积极;图案 ']\n",
      "Contents ['我很喜欢这套冰箱贴，以我个人角度去解读这款故宫•四季设计理念（设计师不要打我[捂脸]）       角楼筒子河畔，柳枝低垂泛绿，随着清风徐来，丝丝翠柳飘动，春光旖旎，莺歌燕啼。        气势磅礴的太和殿在酷暑难耐的夏季显得更加金碧辉煌、威严壮观。       秋日夕阳把乾清门映衬得流光溢彩、华贵富丽，两侧列铜鎏金狮子也显得威风凛凛的。       在银装素裹的冬季，白雪皑皑，午门更加庄严肃穆。 再说一下TA的功能：既可以当冰箱贴，还可以当徽章。设计理念及品控相当不错，推荐']\n",
      "Resps ['我很喜欢这套冰箱贴，以我个人角度去解读这款故宫•四季设计理念（设计师不要打我[捂脸]）;积极;文化']\n",
      "Contents ['感觉质量还是比较好的，与卖家描述的还是一致的，很满意，发货速度比较快，物流公司服务态度好，运送速度快，总的来说这次是很满意的一次购物，感谢卖家 产品功能：好 外观材质：好 商品品质：好\\r 浏览8次']\n",
      "Resps ['感觉质量还是比较好的，与卖家描述的还是一致的，很满意，发货速度比较快，物流公司服务态度好，运送速度快，总的来说这次是很满意的一次购物，感谢卖家;积极;品质']\n",
      "Contents ['感觉质量还是比较好的，与卖家描述的还是一致的，非常满意，发货速度比较快，物流公司服务态度很好，运送速度很快，总的来说这次是很满意的一次购物，感谢卖家。 客服服务态度极好，很有耐心、给人一种亲切感，好喜欢。还有包装精美，高端大气上档次;看得出来商家很用心。宝贝真心不错，与图片相符，没有任何差异，真的是物超所值。']\n",
      "注：此时GPT的回复数缺失！已经靠后补全\n",
      "Resps ['感觉质量还是比较好的，与卖家描述的还是一致的，非常满意，发货速度比较快，物流公司服务态度很好，运送速度很快，总的来说这次是很满意的一次购物，感谢卖家;积极;品质', ' 客服服务态度极好，很有耐心、给人一种亲切感，好喜欢。还有包装精美，高端大气上档次;看得出来商家很用心。宝贝真心不错，与图片相符，没有任何差异，真的是物超所值;积极;包装']\n",
      "Fail to parse  客服服务态度极好，很有耐心、给人一种亲切感，好喜欢。还有包装精美，高端大气上档次;看得出来商家很用心。宝贝真心不错，与图片相符，没有任何差异，真的是物超所值;积极;包装\n",
      "Contents ['️']\n",
      "Resps [\"I'm sorry, but I couldn't understand your input. Can you please provide a user review?\"]\n",
      "Fail to parse I'm sorry, but I couldn't understand your input. Can you please provide a user review?\n",
      "Contents ['️']\n",
      "Resps [\"I'm sorry, but I need an input to analyze. Could you please provide me with a user review or feedback for analysis?\"]\n",
      "Fail to parse I'm sorry, but I need an input to analyze. Could you please provide me with a user review or feedback for analysis?\n",
      "Contents ['️']\n",
      "Resps ['请您输入一条用户评价，我将根据评价内容进行分析。']\n",
      "Fail to parse 请您输入一条用户评价，我将根据评价内容进行分析。\n",
      "Contents ['️']\n",
      "Resps [\"I apologize, but I'm unable to assist with your request.\"]\n",
      "Fail to parse I apologize, but I'm unable to assist with your request.\n",
      "Contents ['️']\n",
      "Resps ['对不起，我没有收到你的评价。你可以再次输入你的评价，谢谢！']\n",
      "Fail to parse 对不起，我没有收到你的评价。你可以再次输入你的评价，谢谢！\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unparsed_indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     11\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContents\u001b[39m\u001b[38;5;124m\"\u001b[39m, unparsed_contents)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 最后几条容易复述失败的模型，单条喂给GPT：\n",
    "while True:\n",
    "    unparsed_indices = []\n",
    "    unparsed_contents = []\n",
    "    for i in range(0, len(df)):\n",
    "        if df.loc[i, 'gpt_emotion'] == \"\":\n",
    "            unparsed_indices.append(i)\n",
    "            unparsed_contents.append(df.loc[i, 'content'])\n",
    "            if len(unparsed_indices) == 1:\n",
    "                break\n",
    "    time.sleep(0.5)\n",
    "    print(\"Contents\", unparsed_contents)\n",
    "    try:\n",
    "        resps = get_gpt_response(unparsed_contents)\n",
    "    except:\n",
    "        continue\n",
    "    print(\"Resps\", resps)\n",
    "    for r in resps:\n",
    "        try:\n",
    "            content, emotion, factor = r.split(\";\")\n",
    "            df.loc[i, 'gpt_emotion'] = emotion\n",
    "            df.loc[i, 'gpt_factor'] = factor\n",
    "        except:\n",
    "            print(\"Fail to parse\", r)\n",
    "    df.to_csv(\"data/ChatGPT分析结果.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0' 'Unnamed: 0.1'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/ChatGPT分析结果.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\frame.py:4308\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4180\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4186\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4187\u001b[0m ):\n\u001b[0;32m   4188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4189\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4190\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4306\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4310\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4314\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4315\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4153\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\generic.py:4188\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4188\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{axis_name: new_axis})\n\u001b[0;32m   4191\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zf\\.conda\\envs\\learn\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5592\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   5591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 5592\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5593\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   5594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0' 'Unnamed: 0.1'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "df.to_csv(\"data/ChatGPT分析结果.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>content</th>\n",
       "      <th>reply</th>\n",
       "      <th>gpt_emotion</th>\n",
       "      <th>gpt_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>非常漂亮</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>审美</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>很精致，买来做教师节礼物的</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>实用性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>很好看，但是送礼物了，没有打开看，希望朋友喜欢。</td>\n",
       "      <td></td>\n",
       "      <td>中性</td>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>质量很好，买的很合我心意，棒棒哒！✨需要的亲们可以放心购买</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>品质</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>送给妹** 她很喜欢</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>情感</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>好</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>漂亮</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>造型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>故宫文创yyds！纸质非常好！</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>材质</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼</td>\n",
       "      <td>好评</td>\n",
       "      <td></td>\n",
       "      <td>积极</td>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208</th>\n",
       "      <td>故宫冯承素摹兰亭序帖卷原大手卷装饰画居家故宫博物院官方</td>\n",
       "      <td>字还是不错的，很有收藏价值，就是盒子换到第三次才没有瑕疵，只能说太不应该了！</td>\n",
       "      <td>亲爱的，您好！很高兴遇到您这样有慧眼、懂文物、又有胸怀的朋友~给您带来的不便我们也真诚的说声...</td>\n",
       "      <td>消极</td>\n",
       "      <td>包装</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10202 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      product_name                                 content  \\\n",
       "0         故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                                    非常漂亮   \n",
       "1         故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                           很精致，买来做教师节礼物的   \n",
       "2         故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                很好看，但是送礼物了，没有打开看，希望朋友喜欢。   \n",
       "3         故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼           质量很好，买的很合我心意，棒棒哒！✨需要的亲们可以放心购买   \n",
       "4         故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                              送给妹** 她很喜欢   \n",
       "...                            ...                                     ...   \n",
       "10204     故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                                       好   \n",
       "10205     故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                                      漂亮   \n",
       "10206     故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                         故宫文创yyds！纸质非常好！   \n",
       "10207     故宫小确幸笔记本日记本礼品本子生日礼物礼品伴手礼                                      好评   \n",
       "10208  故宫冯承素摹兰亭序帖卷原大手卷装饰画居家故宫博物院官方  字还是不错的，很有收藏价值，就是盒子换到第三次才没有瑕疵，只能说太不应该了！   \n",
       "\n",
       "                                                   reply gpt_emotion  \\\n",
       "0                                                                 积极   \n",
       "1                                                                 积极   \n",
       "2                                                                 中性   \n",
       "3                                                                 积极   \n",
       "4                                                                 积极   \n",
       "...                                                  ...         ...   \n",
       "10204                                                             积极   \n",
       "10205                                                             积极   \n",
       "10206                                                             积极   \n",
       "10207                                                             积极   \n",
       "10208  亲爱的，您好！很高兴遇到您这样有慧眼、懂文物、又有胸怀的朋友~给您带来的不便我们也真诚的说声...          消极   \n",
       "\n",
       "      gpt_factor  \n",
       "0             审美  \n",
       "1            实用性  \n",
       "2             其他  \n",
       "3             品质  \n",
       "4             情感  \n",
       "...          ...  \n",
       "10204         其他  \n",
       "10205         造型  \n",
       "10206         材质  \n",
       "10207         其他  \n",
       "10208         包装  \n",
       "\n",
       "[10202 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=df.columns[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = list(range(10202))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
